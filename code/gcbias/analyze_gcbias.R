#!/usr/bin/env Rscript

# clear environment
rm(list=ls())
options(echo=FALSE) # change to TRUE if you want arguments in output file

# quietly load packages
sshhh <- function(a.package){
  suppressWarnings(suppressPackageStartupMessages(
    library(a.package, character.only=TRUE)))
}

# packages to load
auto_loads <- c("optparse","readr","tidyr","dplyr","stringr")

# load them quietly
invisible(lapply(auto_loads, sshhh))

# OPTIONS -----------------------------------------------------------------

options(warn=-1)

description <- "

This script will take in a counts file generated by running bedtools multicov
on a GFF3 formatted file and a nucs file that was generated by running
bedtools nuc on a GFF3 formatted file and transform them into data sets that can
be used to assess the evenness of coverage across transcripts and whether there
is noticable GC bias.

Output: A tab delimited file and rds file containing the processed data

"

option_list <- list(
  make_option(c("-c", "--counts"), type="character",
              help="Counts per window", metavar="character"),
  make_option(c("-n", "--nucs"), type="character",
              help="GC content per window", metavar="character")
)

opt_parser <- OptionParser(option_list=option_list,description=description)
opt <- parse_args(opt_parser)

if (is.null(opt$counts)) {
  print_help(opt_parser)
  stop("\nfile.counts is required\n", call.=FALSE)
}

if (is.null(opt$nucs)) {
  print_help(opt_parser)
  stop("\nfile.nuc is required\n", call.=FALSE)
}


# FUNCTIONS ---------------------------------------------------------------


read_ncol <- function(file) {
  require(readr)
  n <- ncol(read_tsv(file,col_names=F,comment="#"))
  return(n)
}

# MAIN --------------------------------------------------------------------

# Are the input files formatted appropriately?
if(read_ncol(opt$counts) != 17) {
  stop(paste("\n", opt$counts, "does not have the expected number of columns (17)!\n"))
}

if(read_ncol(opt$nucs) != 19) {
  stop(paste("\n", opt$nucs, "does not have the expected number of columns (19)!\n"))
}

# base columns for GFF files
base <- c("chr","source","type","start","stop","score","strand","phase","id")

# Read in necessary inputs and transform to our liking
counts <- read_tsv(opt$counts,
                   col_names=c(base,"tp1","tp2","tp3","tp4","tp5","tp6","tp7","pos")) %>%
  select(id,score,tp1,tp2,tp3,tp4,tp5,tp6,tp7,pos) %>%
  mutate(id=str_replace_all(id,"Parent=rna_","")) %>%
  mutate(id=str_replace_all(id,"-1",""))

nucs <- read_tsv(opt$nucs,skip=1,
                 col_names=c(base,"at","gc","A","C","G","T","N","other","seq_len","pos")) %>%
  select(id,gc,pos) %>%
  mutate(id=str_replace_all(id,"Parent=rna_","")) %>%
  mutate(id=str_replace_all(id,"-1",""))

# Calculate RPKMs per transcript
#tx_rpkms <-

# Calculate RPKMs per 50bp window
rpkms <- counts %>%
  mutate(tp1=((tp1/sum(tp1))/score)*10e6,
         tp2=((tp2/sum(tp2))/score)*10e6,
         tp3=((tp3/sum(tp3))/score)*10e6,
         tp4=((tp4/sum(tp4))/score)*10e6,
         tp5=((tp5/sum(tp5))/score)*10e6,
         tp6=((tp6/sum(tp6))/score)*10e6,
         tp7=((tp7/sum(tp7))/score)*10e6) %>%
  select(-score) %>%
  gather(tp,exp,-id,-pos)

# Calculate median RPKM value for each transcript
medians <- rpkms %>%
  group_by(id,tp) %>%
  summarise(m=median(exp))

# Merge medians and RPKMs to create median normalized data frame
rpkms_norm <- inner_join(rpkms,medians, by=c("id","tp")) %>%
  mutate(exp=ifelse(m>0,exp/m,NA)) %>%
  select(-m)

# Create final data frame
df <- inner_join(rpkms_norm,nucs,by=c("id", "pos"))

# Remove variables to clear up memory
remove("rpkms","rpkms_norm","nucs")

# Write data to a text file and save as .rds file
readr::write_tsv(df,paste0(sub("^([^.]*).*","\\1",opt$counts),".tsv"),col_names=F,na="NA")
saveRDS(df, file = paste0(sub("^([^.]*).*","\\1",opt$counts),".rds"))

# Close R session
q(status=0)
